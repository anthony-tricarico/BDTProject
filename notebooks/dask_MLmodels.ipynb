{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature table created and saved to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "total_seats = 90\n",
    "# --- Configuration ---\n",
    "POSTGRES_URL = \"postgresql+psycopg2://postgres:example@db:5432/raw_data\"\n",
    "\n",
    "# --- Load Data from PostgreSQL ---\n",
    "engine = create_engine(POSTGRES_URL)\n",
    "\n",
    "# Read tables into Dask DataFrames\n",
    "tickets = dd.read_sql_table('raw_tickets', POSTGRES_URL, index_col='timestamp', npartitions=10)\n",
    "tickets = tickets.reset_index()\n",
    "sensors = dd.read_sql_table('raw_sensors', POSTGRES_URL, index_col='timestamp', npartitions=10)\n",
    "sensors = sensors.reset_index()\n",
    "trips = dd.read_sql_table('trips', POSTGRES_URL, index_col='route_id', npartitions=10)\n",
    "traffic = dd.read_sql_table('traffic', POSTGRES_URL, index_col='timestamp', npartitions=10)\n",
    "traffic = traffic.reset_index()\n",
    "weather = dd.read_sql_table('weather', POSTGRES_URL, index_col='measurement_id', npartitions=10)\n",
    "events = dd.read_sql_table('events', POSTGRES_URL, index_col='event_id', npartitions=10)\n",
    "\n",
    "# --- Aggregations (similar to MLmodels.ipynb) ---\n",
    "\n",
    "# Tickets: count passengers in per trip per day\n",
    "tickets['timestamp'] = dd.to_datetime(tickets['timestamp'])\n",
    "tickets['day'] = tickets['timestamp'].dt.date\n",
    "# Extract peak_hour per trip_id (assuming it's consistent per trip)\n",
    "peak_hours = tickets[['trip_id', 'peak_hour']].dropna().drop_duplicates(subset='trip_id')\n",
    "# agg_tickets = tickets.groupby(['trip_id', 'day']).agg({\n",
    "#     'fare': 'count',\n",
    "#     'school': 'max',\n",
    "#     'hospital': 'max',\n",
    "#     'peak_hour': 'max',\n",
    "#     'timestamp': 'max'\n",
    "# }).rename(columns={'fare': 'passengers_in'}).reset_index()\n",
    "tickets['timestamp'] = dd.to_datetime(tickets['timestamp'])\n",
    "tickets['day'] = tickets['timestamp'].dt.date\n",
    "\n",
    "agg_tickets = tickets.groupby(['trip_id', 'day']).agg({\n",
    "    'fare': 'count',\n",
    "    'school': 'max',\n",
    "    'hospital': 'max',\n",
    "    'timestamp': 'max'\n",
    "}).rename(columns={'fare': 'passengers_in'}).reset_index()\n",
    "agg_tickets = dd.merge(agg_tickets, peak_hours, on='trip_id', how='left')\n",
    "\n",
    "# Sensors: count passengers out per trip per day\n",
    "sensors['timestamp'] = dd.to_datetime(sensors['timestamp'])\n",
    "sensors['day'] = sensors['timestamp'].dt.date\n",
    "agg_sensors = sensors.groupby(['trip_id', 'day']).agg({\n",
    "    'status': 'count',\n",
    "    'timestamp': 'max'\n",
    "}).rename(columns={'status': 'passengers_out'}).reset_index()\n",
    "\n",
    "# Merge tickets and sensors\n",
    "merged = dd.merge(agg_tickets, agg_sensors, on=['trip_id', 'day', 'timestamp'], how='inner')\n",
    "\n",
    "# Merge with trips\n",
    "merged = dd.merge(merged, trips.reset_index(), on='trip_id', how='left')\n",
    "\n",
    "# Merge with traffic\n",
    "traffic['timestamp'] = dd.to_datetime(traffic['timestamp'])\n",
    "merged = dd.merge(merged, traffic.reset_index(), on=['shape_id'], how='left')\n",
    "\n",
    "# Merge with weather (asof merge, so convert to pandas for this step)\n",
    "merged_pd = merged.compute()\n",
    "weather_pd = weather.compute()\n",
    "weather_pd['hour'] = pd.to_datetime(weather_pd['hour'])\n",
    "merged_pd['timestamp_x'] = pd.to_datetime(merged_pd['timestamp_x'])\n",
    "merged_pd = pd.merge_asof(\n",
    "    merged_pd.sort_values('timestamp_x'),\n",
    "    weather_pd[['hour', 'temperature', 'precipitation_probability', 'weather_code', 'latitude', 'longitude']].sort_values('hour'),\n",
    "    left_on='timestamp_x', right_on='hour', direction='backward'\n",
    ")\n",
    "\n",
    "# Merge with events (by date)\n",
    "events_pd = events.compute()\n",
    "events_pd['day_event'] = pd.to_datetime(events_pd['day_event']).dt.date\n",
    "merged_pd['day'] = pd.to_datetime(merged_pd['day']).dt.date\n",
    "final = pd.merge(events_pd, merged_pd, left_on='day_event', right_on='day', how='right')\n",
    "final['event_dummy'] = final['day_event'].notna().astype(int)\n",
    "final['total_capacity'] = total_seats\n",
    "final['congestion_rate'] = (final['passengers_in'] - final['passengers_out']) / final['total_capacity']\n",
    "final['seconds_from_midnight'] = (\n",
    "    final['timestamp_x'].dt.hour * 3600 +\n",
    "    final['timestamp_x'].dt.minute * 60 +\n",
    "    final['timestamp_x'].dt.second\n",
    ")\n",
    "# print(final.columns)\n",
    "selected_features = ['trip_id_x', 'peak_hour', 'timestamp_x', 'seconds_from_midnight', 'temperature', 'precipitation_probability', 'weather_code', 'normal', 'traffic', 'traffic_level', 'event_dummy', 'passengers_in', 'passengers_out', 'total_capacity', 'congestion_rate']\n",
    "final = final[selected_features]\n",
    "\n",
    "# --- Save to PostgreSQL ---\n",
    "final_clean = final.dropna()\n",
    "final_dd = dd.from_pandas(final_clean, npartitions=10)\n",
    "# final_dd.to_sql('feature_table', POSTGRES_URL, if_exists='replace', index=False)\n",
    "final_dd.to_sql('feature_table', POSTGRES_URL, if_exists='append', index=False)\n",
    "\n",
    "print(\"Feature table created and saved to PostgreSQL.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect using SQLAlchemy engine\n",
    "with engine.connect() as conn:\n",
    "    # Try to add the unique constraint on (trip_id_x, timestamp_x)\n",
    "    try:\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE feature_table\n",
    "            ADD CONSTRAINT unique_trip_timestamp\n",
    "            UNIQUE (trip_id_x, timestamp_x)\n",
    "        \"\"\"))\n",
    "        print(\"Unique constraint added.\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not add constraint:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
